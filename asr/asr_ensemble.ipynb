{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cb18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sentencepiece\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "from src.models import ConformerLAS, ConformerCTC\n",
    "from src.metrics import WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "28bb692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model: pl.LightningModule, ckpt_path: str) -> pl.LightningModule:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    wer = WER()\n",
    "    wer.update(refs, hyps)\n",
    "    return wer.compute()[0].item()\n",
    "\n",
    "class GreedyDecoderLAS:\n",
    "    def __init__(self, model: ConformerLAS, max_steps=20):\n",
    "        self.model = model\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def __call__(self, encoded: torch.Tensor) -> str:\n",
    "        \n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "\n",
    "        for _ in range(self.max_steps):\n",
    "            \n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "        \n",
    "            best_next_token = distribution[0, -1].argmax()\n",
    "            \n",
    "            if best_next_token == self.model.decoder.tokenizer.eos_id():\n",
    "                break\n",
    "\n",
    "            tokens.append(best_next_token.item())\n",
    "        \n",
    "        return self.model.decoder.tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7489a3",
   "metadata": {},
   "source": [
    "# Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd256ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'test_opus/farfield/farfield.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d7a33",
   "metadata": {},
   "source": [
    "## LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "91eff477",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_las.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "conf.model.decoder.tokenizer = \"./data/tokenizer/bpe_1024_bos_eos.model\"\n",
    "\n",
    "conformer_las = init_model(\n",
    "    model=ConformerLAS(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_las_2epochs.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "1343a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANIFEST_PATH:  /Users/alexandrmaximenko/mipt_tasks/speech-tech-mipt/week09/asr/data/test_opus/farfield/farfield.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8560f46a173434a88fbaf7754841fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "las_decoder = GreedyDecoderLAS(conformer_las)\n",
    "\n",
    "refs, hyps_las = [], []\n",
    "\n",
    "for batch in tqdm(conformer_las.val_dataloader()):\n",
    "\n",
    "    features, features_len, targets, target_len = batch\n",
    "\n",
    "    encoded, encoded_len = conformer_las(features, features_len)\n",
    "    \n",
    "    for i in range(features.shape[0]):\n",
    "\n",
    "        encoder_states = encoded[\n",
    "            [i],\n",
    "            :encoded_len[i],\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        ref_tokens = targets[i, :target_len[i]].tolist()\n",
    "\n",
    "        refs.append(\n",
    "            conformer_las.decoder.tokenizer.decode(ref_tokens)\n",
    "        )\n",
    "        hyps_las.append(\n",
    "            las_decoder(encoder_states)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "d05af7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42290276288986206\n"
     ]
    }
   ],
   "source": [
    "wer_las = compute_wer(refs, hyps_las)\n",
    "print(wer_las)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262680b9",
   "metadata": {},
   "source": [
    "## CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load models, estimate WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "c3e8ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ctc_hyps(model: ConformerCTC) -> Tuple[List[str], List[str]]:\n",
    "    refs, hyps_ctc = [], []\n",
    "\n",
    "    for batch in tqdm(model.val_dataloader()):\n",
    "\n",
    "        features, features_len, targets, target_len = batch\n",
    "\n",
    "        logprobs, encoded_len, preds = model(features, features_len)\n",
    "        \n",
    "        refs_curr = model.decoder.decode(token_ids=targets, token_ids_length=target_len)\n",
    "        \n",
    "        hyps_curr = model.decoder.decode(\n",
    "            token_ids=preds, token_ids_length=encoded_len, unique_consecutive=True\n",
    "        )\n",
    "        refs.extend(refs_curr)\n",
    "        hyps_ctc.extend(hyps_curr)\n",
    "        \n",
    "    return refs, hyps_ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "76da07ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9bc3afa7924a8f9f54f72ea35eb4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc = decode_ctc_hyps(conformer_ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "6deadde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4251968562602997\n"
     ]
    }
   ],
   "source": [
    "wer_ctc = compute_wer(refs, hyps_ctc)\n",
    "print(wer_ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "64281db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5787199612834a62b8f40ce5f57f5412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = omegaconf.OmegaConf.load(\"./conf/conformer_ctc_wide.yaml\")\n",
    "conf.val_dataloader.dataset.manifest_name = dataset\n",
    "\n",
    "conformer_ctc_wide = init_model(\n",
    "    model=ConformerCTC(conf=conf),\n",
    "    ckpt_path=\"./data/conformer_wide_7epochs_state_dict.ckpt\"\n",
    ")\n",
    "\n",
    "refs, hyps_ctc_wide = decode_ctc_hyps(conformer_ctc_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "4bdda104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.369840145111084\n"
     ]
    }
   ],
   "source": [
    "wer_ctc_wide = compute_wer(refs, hyps_ctc_wide)\n",
    "print(wer_ctc_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60776f4",
   "metadata": {},
   "source": [
    "# ROVER: Recognizer Output Voting Error Reduction — 5 points\n",
    "\n",
    "* [A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER)](https://ieeexplore.ieee.org/document/659110)\n",
    "* [Improved ROVER using Language Model Information](https://www-tlp.limsi.fr/public/asr00_holger.pdf)\n",
    "\n",
    "Alignment + Voting\n",
    "\n",
    "![](./images/rover_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "167e04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowdkit.aggregation.texts import ROVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "013b8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_rover = pd.DataFrame(columns=['task', 'text', 'worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "f6a969dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ref in enumerate(refs):\n",
    "    row_ctc_wide = {\n",
    "        'task': i,\n",
    "        'text': hyps_ctc_wide[i],\n",
    "        'worker': 'ctc_wide'\n",
    "    }\n",
    "    row_ctc = {\n",
    "        'task': i,\n",
    "        'text': hyps_ctc[i],\n",
    "        'worker': 'ctc'\n",
    "    }\n",
    "    row_las = {\n",
    "        'task': i,\n",
    "        'text': hyps_las[i],\n",
    "        'worker': 'las'\n",
    "    }\n",
    "    df_for_rover.loc[i*3 ] = pd.Series(row_ctc_wide)\n",
    "    df_for_rover.loc[i*3 + 1] = pd.Series(row_ctc)\n",
    "    df_for_rover.loc[i*3 + 2] = pd.Series(row_las)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fae1d",
   "metadata": {},
   "source": [
    "Добавим кривоватое взвешивание в ROVER из crowdkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "e34cbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from enum import Enum, unique\n",
    "from typing import List, Callable, Dict, Optional, Tuple, cast\n",
    "\n",
    "import attr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from crowdkit.aggregation.base import BaseTextsAggregator\n",
    "\n",
    "\n",
    "@unique\n",
    "class AlignmentAction(Enum):\n",
    "    DELETION = 'DELETION'\n",
    "    SUBSTITUTION = 'SUBSTITUTION'\n",
    "    INSERTION = 'INSERTION'\n",
    "    CORRECT = 'CORRECT'\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class AlignmentEdge:\n",
    "    value: str = attr.ib()\n",
    "    sources_count: Optional[int] = attr.ib()\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class ROVER(BaseTextsAggregator):\n",
    "    \"\"\"Recognizer Output Voting Error Reduction (ROVER).\n",
    "    This method uses dynamic programming to align sequences. Next, aligned sequences are used\n",
    "    to construct the Word Transition Network (WTN):\n",
    "    ![ROVER WTN scheme](https://tlk.s3.yandex.net/crowd-kit/docs/rover.png)\n",
    "    Finally, the aggregated sequence is the result of majority voting on each edge of the WTN.\n",
    "    J. G. Fiscus,\n",
    "    \"A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER),\"\n",
    "    *1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings*, 1997, pp. 347-354.\n",
    "    <https://doi.org/10.1109/ASRU.1997.659110>\n",
    "    Args:\n",
    "        tokenizer: A callable that takes a string and returns a list of tokens.\n",
    "        detokenizer: A callable that takes a list of tokens and returns a string.\n",
    "        silent: If false, show a progress bar.\n",
    "    Examples:\n",
    "        >>> from crowdkit.aggregation import load_dataset\n",
    "        >>> from crowdkit.aggregation import ROVER\n",
    "        >>> df, gt = load_dataset('crowdspeech-test-clean')\n",
    "        >>> df['text'] = df['text'].apply(lambda s: s.lower())\n",
    "        >>> tokenizer = lambda s: s.split(' ')\n",
    "        >>> detokenizer = lambda tokens: ' '.join(tokens)\n",
    "        >>> result = ROVER(tokenizer, detokenizer).fit_predict(df)\n",
    "    Attributes:\n",
    "        texts_ (Series): Tasks' texts.\n",
    "            A pandas.Series indexed by `task` such that `result.loc[task, text]`\n",
    "            is the task's text.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: Callable[[str], List[str]] = attr.ib()\n",
    "    detokenizer: Callable[[List[str]], str] = attr.ib()\n",
    "    silent: bool = attr.ib(default=True)\n",
    "\n",
    "    # Available after fit\n",
    "    # texts_\n",
    "\n",
    "    def fit(self, data: pd.DataFrame, weights: List[float]) -> 'ROVER':\n",
    "        \"\"\"Fits the model. The aggregated results are saved to the `texts_` attribute.\n",
    "        Args:\n",
    "            data (DataFrame): Workers' text outputs.\n",
    "                A pandas.DataFrame containing `task`, `worker` and `text` columns.\n",
    "        Returns:\n",
    "            ROVER: self.\n",
    "        \"\"\"\n",
    "\n",
    "        result = {}\n",
    "        grouped_tasks = data.groupby('task') if self.silent else tqdm(data.groupby('task'))\n",
    "        for task, df in grouped_tasks:\n",
    "            hypotheses = [self.tokenizer(text) for i, text in enumerate(df['text'])]\n",
    "\n",
    "            edges = self._build_word_transition_network(hypotheses, weights)\n",
    "            rover_result = self._get_result(edges)\n",
    "\n",
    "            text = self.detokenizer([value for value in rover_result if value != ''])\n",
    "\n",
    "            result[task] = text\n",
    "\n",
    "        texts = pd.Series(result, name='text')\n",
    "        texts.index.name = 'task'\n",
    "        self.texts_ = texts\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, data: pd.DataFrame, weights) -> pd.Series:\n",
    "        \"\"\"Fit the model and return the aggregated texts.\n",
    "        Args:\n",
    "            data (DataFrame): Workers' text outputs.\n",
    "                A pandas.DataFrame containing `task`, `worker` and `text` columns.\n",
    "        Returns:\n",
    "            Series: Tasks' texts.\n",
    "                A pandas.Series indexed by `task` such that `result.loc[task, text]`\n",
    "                is the task's text.\n",
    "        \"\"\"\n",
    "\n",
    "        self.fit(data, weights)\n",
    "        return self.texts_\n",
    "\n",
    "    def _build_word_transition_network(self, hypotheses: List[List[str]], weights: List[float]) -> List[Dict[str, AlignmentEdge]]:\n",
    "        edges = [{edge.value: edge} for edge in self._get_edges_for_words(hypotheses[0], weights[0])]\n",
    "\n",
    "        for sources_count, hyp in enumerate(hypotheses[1:], start=1):\n",
    "            edges = self._align(edges, self._get_edges_for_words(hyp, weights[sources_count]), sources_count, weights[sources_count])\n",
    "\n",
    "        return edges\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_edges_for_words(words: List[str], weight: float) -> List[AlignmentEdge]:\n",
    "        return [AlignmentEdge(word, weight) for word in words]\n",
    "\n",
    "    @staticmethod\n",
    "    def _align(\n",
    "            ref_edges_sets: List[Dict[str, AlignmentEdge]],\n",
    "            hyp_edges: List[AlignmentEdge],\n",
    "            sources_count: int,\n",
    "            weight: float\n",
    "    ) -> List[Dict[str, AlignmentEdge]]:\n",
    "        \"\"\"Sequence alignment algorithm implementation.\n",
    "        Aligns a sequence of sets of tokens (edges) with a sequence of tokens using dynamic programming algorithm. Look\n",
    "        for section 2.1 in <https://doi.org/10.1109/ASRU.1997.659110> for implementation details. Penalty for\n",
    "        insert/deletion or mismatch is 1.\n",
    "        Args:\n",
    "           ref_edges_sets: Sequence of sets formed from previously aligned sequences.\n",
    "           hyp_edges: Tokens from hypothesis (currently aligned) sequence.\n",
    "           sources_count: Number of previously aligned sequences.\n",
    "        \"\"\"\n",
    "\n",
    "        distance = np.zeros((len(hyp_edges) + 1, len(ref_edges_sets) + 1))\n",
    "        distance[:, 0] = np.arange(len(hyp_edges) + 1)\n",
    "        distance[0, :] = np.arange(len(ref_edges_sets) + 1)\n",
    "\n",
    "        memoization: List[List[Optional[Tuple[AlignmentAction, Dict[str, AlignmentEdge], AlignmentEdge]]]] = [\n",
    "            [None] * (len(ref_edges_sets) + 1) for _ in range(len(hyp_edges) + 1)\n",
    "        ]\n",
    "\n",
    "        for i, hyp_edge in enumerate(hyp_edges, start=1):\n",
    "            memoization[i][0] = (\n",
    "                AlignmentAction.INSERTION,\n",
    "                {'': AlignmentEdge('', sources_count)},\n",
    "                hyp_edge,\n",
    "            )\n",
    "        for i, ref_edges in enumerate(ref_edges_sets, start=1):\n",
    "            memoization[0][i] = (\n",
    "                AlignmentAction.DELETION,\n",
    "                ref_edges,\n",
    "                AlignmentEdge('', 1),\n",
    "            )\n",
    "\n",
    "        # find alignment minimal cost using dynamic programming algorithm\n",
    "        for i, hyp_edge in enumerate(hyp_edges, start=1):\n",
    "            hyp_word = hyp_edge and hyp_edge.value\n",
    "            for j, ref_edges in enumerate(ref_edges_sets, start=1):\n",
    "                ref_words_set = ref_edges.keys()\n",
    "                is_hyp_word_in_ref = hyp_word in ref_words_set\n",
    "\n",
    "                options = []\n",
    "\n",
    "                if is_hyp_word_in_ref:\n",
    "                    options.append((\n",
    "                        distance[i - 1, j - 1],\n",
    "                        (\n",
    "                            AlignmentAction.CORRECT,\n",
    "                            ref_edges,\n",
    "                            hyp_edge,\n",
    "                        )\n",
    "                    ))\n",
    "                else:\n",
    "                    options.append((\n",
    "                        distance[i - 1, j - 1] + 1,\n",
    "                        (\n",
    "                            AlignmentAction.SUBSTITUTION,\n",
    "                            ref_edges,\n",
    "                            hyp_edge,\n",
    "                        )\n",
    "                    ))\n",
    "                options.append((\n",
    "                    distance[i, j - 1] + ('' not in ref_edges),\n",
    "                    (\n",
    "                        AlignmentAction.DELETION,\n",
    "                        ref_edges,\n",
    "                        AlignmentEdge('', 1),\n",
    "                    )\n",
    "                ))\n",
    "                options.append((\n",
    "                    distance[i - 1, j] + 1,\n",
    "                    (\n",
    "                        AlignmentAction.INSERTION,\n",
    "                        {'': AlignmentEdge('', sources_count)},\n",
    "                        hyp_edge,\n",
    "                    )\n",
    "                ))\n",
    "\n",
    "                distance[i, j], memoization[i][j] = min(options, key=lambda t: t[0])  # type: ignore\n",
    "\n",
    "        alignment = []\n",
    "        i = len(hyp_edges)\n",
    "        j = len(ref_edges_sets)\n",
    "\n",
    "        # reconstruct answer from dp array\n",
    "        while i != 0 or j != 0:\n",
    "            action, ref_edges, hyp_edge = cast(Tuple[AlignmentAction, Dict[str, AlignmentEdge], AlignmentEdge],\n",
    "                                               memoization[i][j])\n",
    "            joined_edges = deepcopy(ref_edges)\n",
    "            hyp_edge_word = hyp_edge.value\n",
    "            if hyp_edge_word not in joined_edges:\n",
    "                joined_edges[hyp_edge_word] = hyp_edge\n",
    "            else:\n",
    "                # if word is already in set increment sources count for future score calculation\n",
    "                joined_edges[hyp_edge_word].sources_count += weight  # type: ignore\n",
    "            alignment.append(joined_edges)\n",
    "            if action == AlignmentAction.CORRECT or action == AlignmentAction.SUBSTITUTION:\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            elif action == AlignmentAction.INSERTION:\n",
    "                i -= 1\n",
    "            # action == AlignmentAction.DELETION\n",
    "            else:\n",
    "                j -= 1\n",
    "\n",
    "        return alignment[::-1]\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_result(edges: List[Dict[str, AlignmentEdge]]) -> List[str]:\n",
    "        result = []\n",
    "        for edges_set in edges:\n",
    "            _, _, value = max((x.sources_count, len(x.value), x.value) for x in edges_set.values())\n",
    "            result.append(value)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b08cab",
   "metadata": {},
   "source": [
    "Сначала саггрегируем с одинаковыми весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "e4d1336c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35707467794418335"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: aggregate hypotheses, estimate WER\n",
    "tokenizer = lambda s: s.split(' ')\n",
    "detokenizer = lambda tokens: ' '.join(tokens)\n",
    "rover_crowdkit = ROVER(tokenizer, detokenizer)\n",
    "results = rover_crowdkit.fit_predict(df_for_rover, weights=[1, 1, 1])\n",
    "compute_wer(refs, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01bf75",
   "metadata": {},
   "source": [
    "Теперь чуть поменяем веса в кривом взвешенном Rover-е и станет чуть лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "57c37708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.347053200006485"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rover_crowdkit.fit_predict(df_for_rover, weights=[1.5, 1, 1.5])\n",
    "compute_wer(refs, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd329aa4",
   "metadata": {},
   "source": [
    "# MBR: Minimum Bayes Risk — 5 points\n",
    "\n",
    "\n",
    "* [Minimum Bayes Risk Decoding and System\n",
    "Combination Based on a Recursion for Edit Distance](https://danielpovey.com/files/csl11_consensus.pdf)\n",
    "* [mbr-decoding blog-post](https://suzyahyah.github.io/bayesian%20inference/machine%20translation/2022/02/15/mbr-decoding.html)\n",
    "* [Combination of end-to-end and hybrid models for speech recognition](http://www.interspeech2020.org/uploadfile/pdf/Tue-1-8-4.pdf)\n",
    "\n",
    "![](./images/mbr_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "f2576cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим нужную функцию get_hyp_probability в декодер\n",
    "\n",
    "class GreedyDecoderLASv1(GreedyDecoderLAS):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def get_hyp_probability(self, encoded: torch.Tensor, hyp):\n",
    "        tokens = [self.model.decoder.tokenizer.bos_id()]\n",
    "        score = 1\n",
    "        softmax = nn.Softmax()\n",
    "        for i in range(1, len(hyp)):\n",
    "            tokens_batch = torch.tensor(tokens).unsqueeze(0)\n",
    "            att_mask = self.model.make_attention_mask(torch.tensor([tokens_batch.size(-1)]))\n",
    "            \n",
    "            distribution = self.model.decoder(\n",
    "                encoded=encoded, encoded_pad_mask=None,\n",
    "                target=tokens_batch, target_mask=att_mask, target_pad_mask=None\n",
    "            )\n",
    "            \n",
    "            score *= softmax(distribution[0, -1])[hyp[i]]\n",
    "            tokens.append(hyp[i])\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "e3f6b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_decoder = GreedyDecoderLASv1(conformer_las)\n",
    "def get_hyp_prob_las(hyp, encoder_states, las_decoder=las_decoder, conformer_las=conformer_las):\n",
    "    hyp_tokens = [conformer_las.decoder.tokenizer.bos_id()]\n",
    "    hyp_tokens.extend(conformer_las.decoder.tokenizer.tokenize(hyp))\n",
    "    hyp_tokens.append(conformer_las.decoder.tokenizer.eos_id())\n",
    "    return las_decoder.get_hyp_probability(encoder_states, hyp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "0a99cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ \" \", \"а\", \"б\", \"в\", \"г\", \"д\", \"е\", \"ж\", \"з\", \"и\", \"й\", \"к\", \"л\", \"м\", \"н\", \"о\", \"п\", \"р\", \"с\", \"т\", \"у\", \"ф\", \"х\", \"ц\", \"ч\", \"ш\", \"щ\", \"ъ\", \"ы\", \"ь\", \"э\", \"ю\", \"я\" ]\n",
    "token_to_idx = {token: idx for idx, token in enumerate(labels)}\n",
    "\n",
    "def get_hyp_prob_ctc(hyp, model, logprobs, encoded_len):\n",
    "    if '⁇' in hyp:\n",
    "        return None\n",
    "    hyp_tokens = torch.Tensor([int(token_to_idx[token]) for token in hyp]).long()\n",
    "    target_len = len(hyp)\n",
    "    loss = model.ctc_loss(\n",
    "        logprobs, hyp_tokens, torch.Tensor(encoded_len), torch.tensor(target_len)\n",
    "    )\n",
    "    prob = torch.exp(-loss)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "0f5ab1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "def get_distance_matrix(hyps: List[str]):\n",
    "    distance_matrix = np.zeros((len(hyps), len(hyps)))\n",
    "    for i in range(len(hyps)):\n",
    "        for j in range(i + 1, len(hyps)):\n",
    "            distance = editdistance.eval(hyps[i], hyps[j])\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "    return distance_matrix\n",
    "\n",
    "def get_mbr_hyp(hyps, scores, weights=None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(hyps))\n",
    "    hyp_scores = []\n",
    "    distance_matrix = get_distance_matrix(hyps)\n",
    "    for i in range(len(hyps)):\n",
    "        tmp_scores = []\n",
    "        for j in range(len(hyps)):\n",
    "            probs_sum = np.sum(scores[j])\n",
    "            tmp_score = np.dot(distance_matrix[i], scores[j]) / probs_sum\n",
    "            tmp_scores.append(tmp_score)\n",
    "        hyp_scores.append(np.dot(weights, tmp_scores))\n",
    "    return hyps[np.argmin(hyp_scores)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc51da3",
   "metadata": {},
   "source": [
    "Посчитаем скоры моделей для использвания в MBR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "ad2c3499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANIFEST_PATH:  /Users/alexandrmaximenko/mipt_tasks/speech-tech-mipt/week09/asr/data/test_opus/farfield/farfield.jsonl\n",
      "MANIFEST_PATH:  /Users/alexandrmaximenko/mipt_tasks/speech-tech-mipt/week09/asr/data/test_opus/farfield/farfield.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0494b3b2c84e0faf6b9dc38fc95909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "scores_las = []\n",
    "scores_ctc = []\n",
    "scores_ctc_wide = []\n",
    "k = -1\n",
    "\n",
    "for i, batch in tqdm(enumerate(conformer_las.val_dataloader()), total=len(conformer_las.val_dataloader())):\n",
    "    features, features_len, targets, target_len = batch\n",
    "    curr_hyp_las = hyps_las[batch_size * i: batch_size * i + batch_size]\n",
    "    curr_hyp_ctc = hyps_ctc[batch_size * i: batch_size * i + batch_size]\n",
    "    curr_hyp_ctc_wide = hyps_ctc_wide[batch_size * i: batch_size * i + batch_size]\n",
    "    \n",
    "    encoded_las, encoded_len = conformer_las(features, features_len)\n",
    "    logprobs_ctc, encoded_len, preds_ctc = conformer_ctc(features, features_len)\n",
    "    logprobs_ctc_wide, encoded_len, preds_ctc_wide = conformer_ctc_wide(features, features_len)\n",
    "\n",
    "    for i in range(features.shape[0]):\n",
    "        curr_scores_las = []\n",
    "        curr_scores_ctc = []\n",
    "        curr_scores_ctc_wide = []\n",
    "\n",
    "        encoder_states_las = encoded_las[\n",
    "            [i],\n",
    "            :encoded_len[i],\n",
    "            :\n",
    "        ]\n",
    "        \n",
    "        curr_scores_las.append(get_hyp_prob_las(curr_hyp_las[i], encoder_states_las))\n",
    "        curr_scores_las.append(get_hyp_prob_las(curr_hyp_ctc[i], encoder_states_las))\n",
    "        curr_scores_las.append(get_hyp_prob_las(curr_hyp_ctc_wide[i], encoder_states_las))\n",
    "        \n",
    "        curr_scores_ctc.append(\n",
    "            get_hyp_prob_ctc(curr_hyp_las[i], conformer_ctc, logprobs_ctc[i], encoded_len[i])\n",
    "        )\n",
    "        curr_scores_ctc.append(\n",
    "            get_hyp_prob_ctc(curr_hyp_ctc[i], conformer_ctc, logprobs_ctc[i], encoded_len[i])\n",
    "        )\n",
    "        curr_scores_ctc.append(\n",
    "            get_hyp_prob_ctc(curr_hyp_ctc_wide[i], conformer_ctc, logprobs_ctc[i], encoded_len[i])\n",
    "        )\n",
    "        \n",
    "        curr_scores_ctc_wide.append(\n",
    "            get_hyp_prob_ctc(curr_hyp_las[i], conformer_ctc_wide, logprobs_ctc_wide[i], encoded_len[i])\n",
    "        )\n",
    "        curr_scores_ctc_wide.append(\n",
    "            get_hyp_prob_ctc(curr_hyp_ctc[i], conformer_ctc_wide, logprobs_ctc_wide[i], encoded_len[i])\n",
    "        )\n",
    "        curr_scores_ctc_wide.append(\n",
    "            get_hyp_prob_ctc(curr_hyp_ctc_wide[i], conformer_ctc_wide, logprobs_ctc_wide[i], encoded_len[i])\n",
    "        )\n",
    "        \n",
    "        scores_las.append(curr_scores_las)\n",
    "        scores_ctc.append(curr_scores_ctc)\n",
    "        scores_ctc_wide.append(curr_scores_ctc_wide)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "6c6df282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7342934f114c81a4d04e3702dec3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1916 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyps_mbr = []\n",
    "for i in tqdm(range(len(refs))):\n",
    "    hyps = (hyps_las[i], hyps_ctc[i], hyps_ctc_wide[i])\n",
    "    scores = (scores_las[i], scores_ctc[i], scores_ctc_wide[i])\n",
    "    if None in scores_ctc[i]:\n",
    "        hyps = (hyps_ctc[i], hyps_ctc_wide[i])\n",
    "        scores = (scores_ctc[i][1:], scores_ctc_wide[i][1:])\n",
    "    else:\n",
    "        hyps = (hyps_las[i], hyps_ctc[i], hyps_ctc_wide[i])\n",
    "        scores = (scores_las[i], scores_ctc[i], scores_ctc_wide[i])\n",
    "        \n",
    "    hyps_mbr.append(get_mbr_hyp(hyps, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "866e5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER c использованием MBR:  0.3518253266811371\n"
     ]
    }
   ],
   "source": [
    "print('WER c использованием MBR: ', compute_wer(refs, hyps_mbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "f6a812df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e521222e6040f18ff4792f451924a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1916 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER с подобранными руками весами для MBR:  0.344547837972641\n"
     ]
    }
   ],
   "source": [
    "hyps_mbr_weighted = []\n",
    "for i in tqdm(range(len(refs))):\n",
    "    hyps = (hyps_las[i], hyps_ctc[i], hyps_ctc_wide[i])\n",
    "    scores = (scores_las[i], scores_ctc[i], scores_ctc_wide[i])\n",
    "    weights = [1.5, 1, 1.5]\n",
    "    if None in scores_ctc[i]:\n",
    "        hyps = (hyps_ctc[i], hyps_ctc_wide[i])\n",
    "        scores = (scores_ctc[i][1:], scores_ctc_wide[i][1:])\n",
    "        weights = weights[1:]\n",
    "    else:\n",
    "        hyps = (hyps_las[i], hyps_ctc[i], hyps_ctc_wide[i])\n",
    "        scores = (scores_las[i], scores_ctc[i], scores_ctc_wide[i])\n",
    "        \n",
    "        \n",
    "    hyps_mbr_weighted.append(get_mbr_hyp(hyps, scores, weights=weights))\n",
    "\n",
    "print('WER с подобранными руками весами для MBR: ', compute_wer(refs, hyps_mbr_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904938f",
   "metadata": {},
   "source": [
    "Посмотрим еще на OracleWER, интересно знать сколько вообще можно вытянуть из наших гипотез."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "76239a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleWER(WER):\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def update(self, references: List[str], hypotheses: List[List[str]]):\n",
    "        word_errors = 0.0\n",
    "        words = 0.0\n",
    "        for i, ref in enumerate(references):\n",
    "            ref_tokens = ref.split()\n",
    "            curr_hyps = [hyps[i] for hyps in hypotheses]\n",
    "            hyp_tokens = [hyp.split() for hyp in curr_hyps]\n",
    "            dist = min(editdistance.eval(ref_tokens, curr_hyp_tokens) for curr_hyp_tokens in hyp_tokens)\n",
    "            word_errors += dist\n",
    "            words += len(ref_tokens)\n",
    "        self.word_errors = torch.tensor(\n",
    "            word_errors, device=self.word_errors.device, dtype=self.word_errors.dtype\n",
    "        )\n",
    "        self.words = torch.tensor(\n",
    "            words, device=self.words.device, dtype=self.words.dtype\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "ef4b73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_oracle_wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    wer = OracleWER()\n",
    "    wer.update(refs, hyps)\n",
    "    return wer.compute()[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "6aeea96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle WER:  0.282390832901001\n"
     ]
    }
   ],
   "source": [
    "print('Oracle WER: ', compute_oracle_wer(refs, [hyps_las, hyps_ctc, hyps_ctc_wide]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd2d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
